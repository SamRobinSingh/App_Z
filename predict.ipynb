{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.40.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (4.4.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.111.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.2.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.24.5)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.9.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.10.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\ss876\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.8.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.5.5)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\ss876\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.30.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==1.2.0->gradio) (2024.6.1)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==1.2.0->gradio) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (2.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
      "Requirement already satisfied: requests in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ss876\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->gradio) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->gradio) (0.0.4)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->gradio) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ss876\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ss876\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ss876\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.22.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ss876\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "print(keras.__version__)\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad marshal data (unknown type code)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m mobilenet_model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mmobilenet_model\u001b[38;5;241m.\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39mmobilenet_model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Load your trained model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmymodel.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Load the tokenizer\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenizer.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tokenizer_file:\n",
      "File \u001b[1;32mc:\\Users\\ss876\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\saving\\saving_api.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    205\u001b[0m         filepath,\n\u001b[0;32m    206\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    208\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ss876\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ss876\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\generic_utils.py:102\u001b[0m, in \u001b[0;36mfunc_load\u001b[1;34m(code, defaults, closure, globs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mUnicodeEncodeError\u001b[39;00m, binascii\u001b[38;5;241m.\u001b[39mError):\n\u001b[0;32m    101\u001b[0m     raw_code \u001b[38;5;241m=\u001b[39m code\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_unicode_escape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 102\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[43mmarshal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m globs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     globs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: bad marshal data (unknown type code)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import gradio as gr\n",
    "\n",
    "# Load MobileNetV2 model\n",
    "mobilenet_model = MobileNetV2(weights=\"imagenet\")\n",
    "mobilenet_model = Model(inputs=mobilenet_model.inputs, outputs=mobilenet_model.layers[-2].output)\n",
    "\n",
    "# Load your trained model\n",
    "model = tf.keras.models.load_model('mymodel.h5')\n",
    "\n",
    "# Load the tokenizer\n",
    "with open('tokenizer.pkl', 'rb') as tokenizer_file:\n",
    "    tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "# Max caption length\n",
    "max_caption_length = 34\n",
    "\n",
    "# Function to get word from index\n",
    "def get_word_from_index(index, tokenizer):\n",
    "    return next((word for word, idx in tokenizer.word_index.items() if idx == index), None)\n",
    "\n",
    "# Generate caption using the model\n",
    "def predict_caption(image, model, tokenizer, max_caption_length):\n",
    "    # Preprocess the image\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "\n",
    "    # Extract features using MobileNetV2\n",
    "    image_features = mobilenet_model.predict(image, verbose=0)\n",
    "\n",
    "    # Start generating the caption\n",
    "    caption = \"startseq\"\n",
    "    for _ in range(max_caption_length):\n",
    "        sequence = tokenizer.texts_to_sequences([caption])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_caption_length)\n",
    "        yhat = model.predict([image_features, sequence], verbose=0)\n",
    "        predicted_index = np.argmax(yhat)\n",
    "        predicted_word = get_word_from_index(predicted_index, tokenizer)\n",
    "        if predicted_word is None or predicted_word == \"endseq\":\n",
    "            break\n",
    "        caption += \" \" + predicted_word\n",
    "\n",
    "    # Clean up the generated caption\n",
    "    generated_caption = caption.replace(\"startseq\", \"\").replace(\"endseq\", \"\")\n",
    "    return generated_caption\n",
    "\n",
    "# Gradio function to handle image input and generate caption\n",
    "def generate_caption(uploaded_image):\n",
    "    # Convert the uploaded image to array and resize\n",
    "    image = img_to_array(uploaded_image)\n",
    "    image = image.reshape((1, 224, 224, 3))\n",
    "    # Generate the caption\n",
    "    caption = predict_caption(image, model, tokenizer, max_caption_length)\n",
    "    return caption\n",
    "\n",
    "# Gradio interface\n",
    "inputs = gr.inputs.Image(shape=(224, 224), label=\"Upload Image\")\n",
    "outputs = gr.outputs.Textbox(label=\"Generated Caption\")\n",
    "\n",
    "# Create Gradio interface\n",
    "gr.Interface(fn=generate_caption, inputs=inputs, outputs=outputs, \n",
    "             title=\"Image Caption Generator\", \n",
    "             description=\"Upload an image and generate a caption using a trained model.\").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading trained model: bad marshal data (unknown type code)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Failed to load necessary models or tokenizer. Please check the error messages above.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m Failed to load necessary models or tokenizer. Please check the error messages above.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ss876\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import gradio as gr\n",
    "\n",
    "# Function to load the tokenizer\n",
    "def load_tokenizer(tokenizer_path='tokenizer.pkl'):\n",
    "    try:\n",
    "        with open(tokenizer_path, 'rb') as tokenizer_file:\n",
    "            tokenizer = pickle.load(tokenizer_file)\n",
    "        return tokenizer\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading tokenizer: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to load MobileNetV2 model\n",
    "def load_mobilenet():\n",
    "    try:\n",
    "        mobilenet_model = MobileNetV2(weights=\"imagenet\")\n",
    "        mobilenet_model = Model(inputs=mobilenet_model.inputs, outputs=mobilenet_model.layers[-2].output)\n",
    "        return mobilenet_model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading MobileNetV2: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to load your trained model\n",
    "def load_trained_model(model_path='mymodel.h5'):\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading trained model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load all necessary components\n",
    "mobilenet_model = load_mobilenet()\n",
    "model = load_trained_model()\n",
    "tokenizer = load_tokenizer()\n",
    "\n",
    "if mobilenet_model is None or model is None or tokenizer is None:\n",
    "    raise SystemExit(\"Failed to load necessary models or tokenizer. Please check the error messages above.\")\n",
    "\n",
    "# Max caption length\n",
    "max_caption_length = 34\n",
    "\n",
    "# Function to get word from index\n",
    "def get_word_from_index(index, tokenizer):\n",
    "    return next((word for word, idx in tokenizer.word_index.items() if idx == index), None)\n",
    "\n",
    "# Generate caption using the model\n",
    "def predict_caption(image, model, tokenizer, max_caption_length):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        image = preprocess_input(image)\n",
    "\n",
    "        # Extract features using MobileNetV2\n",
    "        image_features = mobilenet_model.predict(image, verbose=0)\n",
    "\n",
    "        # Start generating the caption\n",
    "        caption = \"startseq\"\n",
    "        for _ in range(max_caption_length):\n",
    "            sequence = tokenizer.texts_to_sequences([caption])[0]\n",
    "            sequence = pad_sequences([sequence], maxlen=max_caption_length)\n",
    "            yhat = model.predict([image_features, sequence], verbose=0)\n",
    "            predicted_index = np.argmax(yhat)\n",
    "            predicted_word = get_word_from_index(predicted_index, tokenizer)\n",
    "            if predicted_word is None or predicted_word == \"endseq\":\n",
    "                break\n",
    "            caption += \" \" + predicted_word\n",
    "\n",
    "        # Clean up the generated caption\n",
    "        generated_caption = caption.replace(\"startseq\", \"\").replace(\"endseq\", \"\")\n",
    "        return generated_caption\n",
    "    except Exception as e:\n",
    "        return f\"Error generating caption: {e}\"\n",
    "\n",
    "# Gradio function to handle image input and generate caption\n",
    "def generate_caption(uploaded_image):\n",
    "    try:\n",
    "        # Convert the uploaded image to array and resize\n",
    "        image = img_to_array(uploaded_image)\n",
    "        image = tf.image.resize(image, (224, 224)).numpy()\n",
    "        image = image / 255.0  # Normalize if needed\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "        # Generate the caption\n",
    "        caption = predict_caption(image, model, tokenizer, max_caption_length)\n",
    "        return caption\n",
    "    except Exception as e:\n",
    "        return f\"Error processing image: {e}\"\n",
    "\n",
    "# Gradio interface\n",
    "inputs = gr.Image(type=\"numpy\", shape=(224, 224), label=\"Upload Image\")\n",
    "outputs = gr.Textbox(label=\"Generated Caption\")\n",
    "\n",
    "# Create Gradio interface\n",
    "gr.Interface(\n",
    "    fn=generate_caption,\n",
    "    inputs=inputs,\n",
    "    outputs=outputs, \n",
    "    title=\"Image Caption Generator\", \n",
    "    description=\"Upload an image and generate a caption using a trained model.\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
